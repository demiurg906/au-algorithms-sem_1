# Хеширование

**Постановка задачи:** хотим что-то хранить и искать. Есть множество ключей $K$ и его подмножество $S$, которое мы хотим хранить. Варианты решения:
1. Прямая индексация: заводим массив $a$ длины $|K|$, храним ключ $k$ в ячейке $a[k]$.
    Плюсы: скорость работы $O(1)$
    Минусы: затраты на память $O(|K|)$
2. Дерево поиска
    Плюсы:
    - доступ за $O(\log n)$
    - затраты на память $O(n)$
    Минусы:
    - необходимо отношение порядка на $K$
3. Хеш-таблица
    Плюсы:
    - время работы $O(1)$ в среднем (есть модификация (совершенное хеширование), обеспечивающее $O(1)$ в худшем случае для статической постановки)
    - затраты на память $O(n)$
    Минусы:
    - нужна "хорошая" хеш-функция

## Хеш-функция

*Хеш-функция* $h: K \rightarrow [m]$ (в какое-то подмножество $\mathbb N$ или $\mathbb Z$).

## Хеш-таблица

Храним таблицу размера $m$, в ячейке $m_i$ храним (как-то) элементы $k$ такие, что $h(k) = m_i$

Ключевые вопросы:
1. Выбор $m$ (надо $m \sim |S|$). Если структура динамическая, то $m$ можно увеличивать пр необходимости, как в динамическом списке на массиве.
2. Выбор $h(k)$
3. Разрешение коллизий

### Способы разрешения коллизий

#### Метод цепочек

В ячейках, вместо элементов, храним связные списки (можно однонаправленные). При коллизиии просто идем по этому списку, ищем нужный ключ

**Утверждение:** неуспешный поиск элемента в таблице с цепочками требует $O(1 + \alpha)$, где $\alpha = \frac nm$ -- коэффициент заполения таблицы (сколько в среднем элементов в одной ячейке).
**Доказательство:** $E[\#\text{операций}] = 1 + E[\#\text{длина цепочки}] = 1 + \sum\limits_{k\in T} E[\text{добавка}] = 1 + \frac nm = O(1 + \alpha)$

**Утверждение:** успешный поиск элемента в таблице с цепочками требует $O(1 + \alpha)$ (отличие от предыдущего в том, что если элемент в таблице, то эти рассуждения некорректны).
**Доказательство:** т.к. поиск успешный, то элемент не совсем случайный, он выбирается из тех элементов, которые мы уже видели, вследствие чего гипотеза равномерного хеширования (см. ниже) не работает, и ключ попадет не в любую ячейку таблицы равновероятно, а в конкретную.
    $E[\#\text{опер. по поиску}] = E[\#\text{опер. по добавлению (неуспешный поиск)}] = $
    $=1 + \frac 1n\sum\limits_{i=1}^n1+\frac{i-1}{m} = 1 + \frac 1{nm} \sum\limits_{i=1}^n i - 1 = $
    $ = 1 + \frac{1}{nm}\frac{(n-1)n}{2} = 1 + \frac{n-1}{2m} = O(1 + \alpha)$

#### Метод последовательных проб

В ячейках храним элементы. Если ячейка оказалась занята, то мы пытаемся положить в следующую. Проверяем $\{h(k) + i\}_{i=0}$
При поиске последовательно идем по занятым ячейкам до первой незанятой

Минусы:
* нужно удаление с пометкой
* образуются кластеры

#### Метод квадратичных проб

Та же идея, проверяем индексы $\{h(k) + i\cdot C_1 + i^2\cdot C_2\}_{i=0}$, где $C_1$ и $C_2$ -- какие-то константы. Благодоря этому мы разрежаем наши цепочки по всей таблице.

Минусы те же самые, разве что кластеры образуются реже

#### Метод двойного хеширования

Проверяем $\{h_1(k) + h_2(i, k)\}$, $h_2(0, k) = 0$. Предполагаем гипотезу равномерного хеширования, благодоря ей и второй хеш-функции $h_2$ цепочки разносятся равномерно по всей таблице

**Утверждение:** неуспешный поиск элемента требует $O(\frac{1}{1 - \alpha})$, $\alpha \leq 1$.
**Доказательство:** $E[\#\text{операций}] = 1\cdot(1 - \alpha) + 2\cdot\alpha(1-\alpha) + 3\cdot\alpha^2(1 - \alpha) + ... =$
    $=(1-\alpha)\sum\limits_{i=1}^{\infty}i\cdot\alpha^{i-1} = (1 - \alpha)\cdot \frac{1}{(1 - \alpha)^2} = O(\frac{1}{1 - \alpha})$

**Утверждение:** успешный поиск элемента требует $O(\frac{1}{\alpha}\cdot\ln\frac{1}{1 - \alpha})$
**Доказательство:** также оцениваем количество операций по добавлению.
    $E[\#\text{опер. по поиску}] = E[\#\text{опер. по добавлению}] =$
    $ = 1 + \frac 1n\sum\limits_{i=1}^n\frac{1}{1 - \frac{i - 1}{m}} = \frac 1n\sum\limits_{i=1}^n\frac{m}{m + 1 - i} = \frac mn \sum\limits_{x=m + 1 - n}^m\frac 1x \leq$
    $\leq \frac mn \int\limits_{m-n}^m\frac 1x dx = \frac mn \ln\frac m{m-n} = \frac{1}{\alpha}\cdot\ln\frac{1}{1 - \alpha}$
## Примеры хеш-функций

1. $K = \mathbb Z$. Тогда $h(k) = k \mod m$
2. $K = [0, 1]$. Тогда $h(k) = [m \cdot k] \mod m$, где $[x]$ -- целая часть
3. $K = \mathbb Z$. Тогда $h(k) = [m\cdot \{A \cdot k \mod k\}]$, $A$ -- какое-то иррациональное число (например $\varphi$), $\{x\}$ -- дробная часть (обрабатывает какие-то краевые эффекты).
4. $K = \Sigma^* $ (ключи -- строки). Тогда $h(k)$ -- полиномиальный хеш

## Полиномиальные хеши

Пусть есть строка $s = s_0s_1...s_n$.

Тогда хеш-функция: $h_x(s) = x^n \cdot s_0 + x^{n-1} \cdot s_1 + ... + x\cdot s_{n-1} + s_n \mod m$, где $x$ -- какое-то число, желательно простое.

**Формула пересчета:** $h_x(s_0...s_ns_{n+1}) = x\cdot h_x(s_0...s_n) + s_{n+1}$

### Алгоритм Рабина-Карпа

$T$ -- текст, $P$ -- шаблон. Необходимо проверить, что $P$ входит в $T$.

Алгоритм Р-К решает это за $O(|P| + |T|)$ в среднем.

Пусть $|P| = l$ и $|T| = n$.

**Алгоритм:**
1. Посчитаем все хеши кусочков текста размера $l$: $H = \{h(T_i...T_{i+l-1})\}$
2. Найдем все такие хеши, которые совпали с $h(P)$
3. Проверяем все такие совпадения

Внимание вопрос: как посчитать $H$ за линию?
Ответ: формула пересчета, $H[i + 1] = (H[i] - T[i] \cdot x^{l-1})\cdot x + T[i + l]$

## Хорошие хеш-функции

Хочется, чтобы вероятность $P\left[h(k) = i\right] = \frac 1m$

Проблема: распределение на $K$ неизвестно.

**Гипотеза равномерного хеширования:** давайте считать, что хеш-функция хорошая и $\forall i \in [m]:\ \ P\left[h(k) = i\right] = \frac 1m$.

Теперь, в предположении этой гипотезы, можно оценивать все алгоритмы.

**Следствие:** $P\left[h(k_1) = h(k_2)\right] = \frac 1m$
